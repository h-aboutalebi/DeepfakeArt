

<img src="https://github.com/h-aboutalebi/DeepfakeArt/blob/main/images/logo.jpg" alt="logo" width="600" height="200">
<figure class="image">
<img src="https://github.com/h-aboutalebi/DeepfakeArt/blob/main/images/inpainting.jpg" alt="inpainting">
<figcaption>Generated forgery images from real images using inpainting.</figcaption>
</figure>


# DeepfakeArt Dataset
Introducing the premier dataset designed to encompass various forgery generation techniques derived from original source images. This dataset is specifically crafted to aid in the detection of copyright infringement in generative computer vision models. Boasting over 30,000 records, each entry consists of a pair of images that are either similar (wherein the generated image infringes upon the copyright of the original image) or dissimilar. Each of the generated images in the dataset has been quality checked.

The forgery creation methods implemented in this dataset include:

- Inpainting
- Style Transfer
- Adversarial 
- Segmix
- Cutmix


**The Dataset is available [Visit Dataset](https://www.kaggle.com/datasets/danielmao2019/deepfakeart)**

## Inpainting Category

The source dataset for this category is WikiArt [(ref)](https://paperswithcode.com/paper/large-scale-classification-of-fine-art). Each image is sampled randomly from the dataset as the source image to generate forgery images. 
Each record in this category consists of three images: 

- source image: The source image used to create a forgery image from
- inpainting image: The inpainting image generated by Stable Diffusion 2 model [(ref)](https://huggingface.co/stabilityai/stable-diffusion-2-inpainting)
- masking image: black-white image which white parts depicts which parts of original image is inpainted by Stable Diffusion 2 to generate inpainting image

The prompt used for the generation of the inpainting image is: "generate a painting compatible with the rest of the image"

This category consists of more than 5000 records. The original images are masked between 40%-60%. We applied one of the followed macking schema randomly:

- side masking: where the top side, bottom side, right side or left side of the source image is maked
- diagonal masking: where the upper right, upper left, lower right, or lower left diagonal side of thw source image is masked
- random masking: where randomly selected parts of the source image are masked

The code for the data generation of this part can be found [here](https://github.com/h-aboutalebi/DeepfakeArt/blob/main/image_inpainting/main.py)

## Style Transfer

Images in this section were generated by passing images in the WikiArt dataset to the ControlNet model [(ref)](https://huggingface.co/lllyasviel/ControlNet). Guided by Canny edge detections and prompts, we selected 200 images from each sub-directory of the WikiArt dataset, except for Action_painting and Analytical_Cubism, which contain only 98 and 110 images, respectively. We utilized four distinct prompts for different styles for the generations:

- "a high-quality, detailed, realistic image", 
- "a high-quality, detailed, cartoon style drawing", 
- "a high-quality, detailed, oil painting"
- "a high-quality, detailed, pencil drawing". 

Each prompt was used for a quarter of the images from each sub-directory. Finally, generated outputs of poor quality were discarded, resulting in a total of 3,213 (original, edges, prompt, generated) 4-tuples in this section.
